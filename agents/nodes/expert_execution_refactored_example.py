"""Expert Execution Node é‡æ„ç¤ºä¾‹ã€‚

æ­¤æ–‡ä»¶å±•ç¤ºäº†å¦‚ä½•å°† expert_execution_node é‡æ„ä¸ºä½¿ç”¨ LangGraph æ ‡å‡†åšæ³•ï¼š
1. ä½¿ç”¨ llm.bind_tools() ç»‘å®šå·¥å…·
2. ä½¿ç”¨ ToolNode æ‰§è¡Œå·¥å…·è°ƒç”¨
3. ä½¿ç”¨ LCEL è¯­æ³•

æ³¨æ„ï¼šè¿™æ˜¯ä¸€ä¸ªç¤ºä¾‹æ–‡ä»¶ï¼Œå±•ç¤ºé‡æ„æ–¹å‘ã€‚å®é™…é‡æ„éœ€è¦æ›´ä»”ç»†çš„æµ‹è¯•ã€‚
"""

import asyncio
import logging
from typing import Dict, Any, List, Optional
from langchain_core.messages import HumanMessage, AIMessage, ToolMessage
from langgraph.prebuilt import ToolNode
from core.state import ReviewState, RiskItem
from core.langchain_llm import LangChainLLMAdapter
from agents.prompts import render_prompt_template

logger = logging.getLogger(__name__)


async def expert_execution_node_refactored(state: ReviewState) -> Dict[str, Any]:
    """é‡æ„åçš„ Expert Execution Nodeï¼ˆç¤ºä¾‹ï¼‰ã€‚
    
    é‡æ„è¯´æ˜ï¼š
    1. ä½¿ç”¨ llm.bind_tools() ç»‘å®šå·¥å…·åˆ°æ¨¡å‹
    2. ä½¿ç”¨ ToolNode æ‰§è¡Œå·¥å…·è°ƒç”¨ï¼ˆæ›¿ä»£æ‰‹åŠ¨è§£æï¼‰
    3. ä½¿ç”¨ messages å­—æ®µç®¡ç†å¯¹è¯å†å²ï¼ˆLangGraph æ ‡å‡†ï¼‰
    4. ä½¿ç”¨ LCEL è¯­æ³•è¿›è¡Œæç¤ºå’Œè§£æ
    
    Args:
        state: Current workflow state with expert_tasks.
    
    Returns:
        Dictionary with 'expert_results' key.
    """
    print("\n" + "="*80)
    print("ğŸ”¬ [èŠ‚ç‚¹3] Expert Execution (é‡æ„ç‰ˆ) - ä½¿ç”¨ LangGraph æ ‡å‡†å·¥å…·è°ƒç”¨")
    print("="*80)
    
    # è·å–ä¾èµ–
    llm_adapter: LangChainLLMAdapter = state.get("metadata", {}).get("llm_adapter")
    langchain_tools = state.get("metadata", {}).get("langchain_tools", [])
    
    if not llm_adapter:
        logger.error("LLM adapter not found in metadata")
        return {"expert_results": {}}
    
    # é‡æ„è¯´æ˜ï¼šä½¿ç”¨ ToolNode æ‰§è¡Œå·¥å…·è°ƒç”¨
    tool_node = ToolNode(langchain_tools)
    
    # é‡æ„è¯´æ˜ï¼šä½¿ç”¨ llm.bind_tools() ç»‘å®šå·¥å…·
    bound_llm = llm_adapter.bind_tools(langchain_tools)
    
    expert_tasks_dicts = state.get("expert_tasks", {})
    if not expert_tasks_dicts:
        return {"expert_results": {}}
    
    # è½¬æ¢ä»»åŠ¡
    from core.state import RiskItem
    expert_tasks = {
        risk_type: [RiskItem(**item) if isinstance(item, dict) else item for item in items]
        for risk_type, items in expert_tasks_dicts.items()
    }
    
    # å¤„ç†æ¯ä¸ªä¸“å®¶ç»„
    expert_results = {}
    for risk_type_str, risk_items in expert_tasks.items():
        results = await _process_expert_group_refactored(
            risk_type_str=risk_type_str,
            tasks=risk_items,
            state=state,
            bound_llm=bound_llm,
            tool_node=tool_node
        )
        expert_results[risk_type_str] = results
    
    # è½¬æ¢ç»“æœ
    expert_results_dicts = {
        risk_type: [item.model_dump() for item in items]
        for risk_type, items in expert_results.items()
    }
    
    return {"expert_results": expert_results_dicts}


async def _process_expert_group_refactored(
    risk_type_str: str,
    tasks: List[RiskItem],
    state: ReviewState,
    bound_llm: Any,
    tool_node: ToolNode
) -> List[RiskItem]:
    """å¤„ç†ä¸“å®¶ç»„ä»»åŠ¡ï¼ˆé‡æ„ç‰ˆï¼‰ã€‚
    
    é‡æ„è¯´æ˜ï¼š
    - ä½¿ç”¨ bound_llm è°ƒç”¨æ¨¡å‹ï¼ˆæ¨¡å‹å¯ä»¥è¿”å›å·¥å…·è°ƒç”¨ï¼‰
    - ä½¿ç”¨ tool_node æ‰§è¡Œå·¥å…·è°ƒç”¨
    - ä½¿ç”¨ messages å­—æ®µç®¡ç†å¯¹è¯å†å²
    
    Args:
        risk_type_str: Risk type string.
        tasks: List of RiskItem objects.
        state: Global workflow state.
        bound_llm: LLM with tools bound.
        tool_node: ToolNode for executing tool calls.
    
    Returns:
        List of validated RiskItem objects.
    """
    results = []
    
    for task in tasks:
        try:
            # åˆ›å»ºåˆå§‹æç¤º
            initial_prompt = render_prompt_template(
                f"expert_{risk_type_str}",
                risk_item=task.model_dump(),
                file_path=task.file_path,
                line_number=task.line_number,
                description=task.description,
                diff_context=state.get("diff_context", ""),
                available_tools=", ".join([tool.name for tool in langchain_tools])
            )
            
            # é‡æ„è¯´æ˜ï¼šä½¿ç”¨ messages å­—æ®µç®¡ç†å¯¹è¯å†å²
            messages = state.get("messages", [])
            messages.append(HumanMessage(content=initial_prompt))
            
            # é‡æ„è¯´æ˜ï¼šä½¿ç”¨ bound_llm è°ƒç”¨æ¨¡å‹ï¼ˆå¯ä»¥è¿”å›å·¥å…·è°ƒç”¨ï¼‰
            max_iterations = 10
            for iteration in range(max_iterations):
                # è°ƒç”¨æ¨¡å‹
                response = await bound_llm.ainvoke(messages)
                messages.append(response)
                
                # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
                if hasattr(response, "tool_calls") and response.tool_calls:
                    # é‡æ„è¯´æ˜ï¼šä½¿ç”¨ ToolNode æ‰§è¡Œå·¥å…·è°ƒç”¨
                    tool_messages = await tool_node.ainvoke(response.tool_calls)
                    messages.extend(tool_messages)
                    # ç»§ç»­å¾ªç¯ï¼Œè®©æ¨¡å‹åŸºäºå·¥å…·ç»“æœç»§ç»­åˆ†æ
                else:
                    # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œè¿™æ˜¯æœ€ç»ˆç­”æ¡ˆ
                    break
            
            # è§£ææœ€ç»ˆå“åº”
            validated_item = _parse_final_response(response.content, task)
            results.append(validated_item)
            
        except Exception as e:
            logger.error(f"Error processing task: {e}")
            continue
    
    return results


def _parse_final_response(response: str, original_item: RiskItem) -> RiskItem:
    """è§£ææœ€ç»ˆå“åº”ã€‚
    
    é‡æ„è¯´æ˜ï¼š
    - å¯ä»¥ä½¿ç”¨ PydanticOutputParser æ›¿ä»£æ‰‹åŠ¨è§£æ
    - æˆ–è€…ä½¿ç”¨ç»“æ„åŒ–è¾“å‡ºï¼ˆå¦‚æœ LLM æ”¯æŒï¼‰
    
    Args:
        response: LLM response string.
        original_item: Original risk item.
    
    Returns:
        Validated RiskItem.
    """
    # è¿™é‡Œå¯ä»¥ä½¿ç”¨ PydanticOutputParser æˆ–ç»“æ„åŒ–è¾“å‡º
    # ä¸ºäº†ç®€åŒ–ï¼Œè¿™é‡Œä¿æŒåŸæœ‰çš„è§£æé€»è¾‘
    import json
    try:
        data = json.loads(response)
        return RiskItem(
            risk_type=RiskType(data.get("risk_type", original_item.risk_type.value)),
            file_path=data.get("file_path", original_item.file_path),
            line_number=data.get("line_number", original_item.line_number),
            description=data.get("description", original_item.description),
            confidence=float(data.get("confidence", original_item.confidence)),
            severity=data.get("severity", original_item.severity),
            suggestion=data.get("suggestion", original_item.suggestion)
        )
    except:
        return original_item
