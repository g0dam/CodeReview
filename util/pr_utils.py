"""PRï¼ˆæ‹‰å–è¯·æ±‚ï¼‰å¤„ç†å·¥å…·ï¼Œç”¨äº diff åŠ è½½å’Œç»“æœæ ¼å¼åŒ–ã€‚"""

import json
from pathlib import Path
from typing import Optional

from core.config import Config
from util.git_utils import get_repo_name
from util.logger import save_observations_to_log


def load_diff_from_file(file_path: Path) -> str:
    """ä»æ–‡ä»¶åŠ è½½ Git diffã€‚
    
    Raises:
        FileNotFoundError: æ–‡ä»¶ä¸å­˜åœ¨ã€‚
        IOError: æ–‡ä»¶æ— æ³•è¯»å–ã€‚
    """
    file_path = Path(file_path).resolve()
    
    if not file_path.exists():
        raise FileNotFoundError(f"Diff file not found: {file_path}")
    
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            return f.read()
    except Exception as e:
        raise IOError(f"Error reading diff file: {e}")


def print_review_results(results: dict, workspace_root: Optional[Path] = None, config: Optional[Config] = None) -> None:
    """ä»¥æ ¼å¼åŒ–æ–¹å¼æ‰“å°å®¡æŸ¥ç»“æœã€‚"""
    print("\n" + "=" * 80)
    print("CODE REVIEW RESULTS")
    print("=" * 80)
    
    # Changed files (for multi-agent workflow) or focus files (for old workflow)
    changed_files = results.get("changed_files", [])
    focus_files = results.get("focus_files", [])
    files_to_show = changed_files if changed_files else focus_files
    
    print(f"\nğŸ“‹ Changed Files ({len(files_to_show)}):")
    if files_to_show:
        for i, file_path in enumerate(files_to_show, 1):
            print(f"  {i}. {file_path}")
    else:
        print("  (none)")
    
    # Issues - support both old format (identified_issues) and new format (confirmed_issues)
    identified_issues = results.get("identified_issues", [])
    confirmed_issues = results.get("confirmed_issues", [])
    issues = confirmed_issues if confirmed_issues else identified_issues
    
    print(f"\nğŸ” Issues Found ({len(issues)}):")
    
    if not issues:
        print("  âœ… No issues found!")
    else:
        # Group by severity
        by_severity = {"error": [], "warning": [], "info": []}
        for issue in issues:
            # Support both old format (severity) and new format (RiskItem with severity)
            severity = issue.get("severity", "info")
            by_severity.get(severity, by_severity["info"]).append(issue)
        
        for severity in ["error", "warning", "info"]:
            severity_issues = by_severity[severity]
            if severity_issues:
                icon = {"error": "âŒ", "warning": "âš ï¸", "info": "â„¹ï¸"}[severity]
                print(f"\n  {icon} {severity.upper()} ({len(severity_issues)}):")
                for issue in severity_issues:
                    # Support both old format and new RiskItem format
                    file_path = issue.get("file_path") or issue.get("file", "unknown")
                    line_number = issue.get("line_number") or issue.get("line", 0)
                    # Format line number range: (10, 15) -> "10:15", (10, 10) or 10 -> "10"
                    if isinstance(line_number, (list, tuple)) and len(line_number) == 2:
                        start, end = line_number
                        line = f"{start}:{end}" if start != end else str(start)
                    else:
                        line = str(line_number) if line_number else "0"
                    message = issue.get("description") or issue.get("message", "")
                    suggestion = issue.get("suggestion", "")
                    risk_type = issue.get("risk_type", "")
                    confidence = issue.get("confidence")
                    
                    # Format risk type if available
                    risk_type_str = f" [{risk_type}]" if risk_type else ""
                    confidence_str = f" (confidence: {confidence:.2f})" if confidence is not None else ""
                    
                    print(f"    â€¢ {file_path}:{line}{risk_type_str}{confidence_str}")
                    print(f"      {message}")
                    if suggestion:
                        print(f"      ğŸ’¡ Suggestion: {suggestion}")
    
    # Final report (for multi-agent workflow)
    final_report = results.get("final_report", "")
    if final_report:
        print(f"\nğŸ“„ Final Report:")
        print("  " + "=" * 76)
        # Print first 500 characters of the report
        report_preview = final_report[:500] + "..." if len(final_report) > 500 else final_report
        for line in report_preview.split("\n"):
            print(f"  {line}")
        if len(final_report) > 500:
            print(f"  ... (truncated, {len(final_report)} total characters)")
        print("  " + "=" * 76)
    
    # Metadata (skip langchain_tools and other verbose fields)
    metadata = results.get("metadata", {})
    if metadata:
        print(f"\nğŸ“Š Metadata:")
        for key, value in metadata.items():
            # Skip printing observations in metadata (will be in log file)
            if key == "agent_observations":
                print(f"  â€¢ {key}: [{len(value) if isinstance(value, list) else 0} observations] (saved to log)")
            elif key == "agent_tool_results":
                print(f"  â€¢ {key}: [{len(value) if isinstance(value, list) else 0} tool calls] (saved to log)")
            elif key == "expert_analyses":
                print(f"  â€¢ {key}: [{len(value) if isinstance(value, list) else 0} expert analyses] (saved to log)")
            elif key in ["llm_provider", "config", "tools", "langchain_tools"]:
                # Skip non-serializable objects and langchain_tools
                continue
            else:
                print(f"  â€¢ {key}: {value}")
    
    # Save observations and expert analyses to log files
    if workspace_root and config:
        try:
            log_file = save_observations_to_log(results, workspace_root, config)
            if log_file:
                print(f"\nğŸ“ Logs saved:")
                print(f"   â€¢ Expert Analyses: {log_file}")
        except Exception as e:
            print(f"\nâš ï¸  Warning: Could not save logs: {e}")
    
    print("\n" + "=" * 80)


def make_results_serializable(obj: dict) -> dict:
    """ç§»é™¤å­—å…¸ä¸­çš„ä¸å¯åºåˆ—åŒ–å¯¹è±¡ï¼ˆå¦‚ ChatModelã€Configã€toolsï¼‰ã€‚
    
    åŒæ—¶ä¼˜åŒ–ç»“æœç»“æ„ï¼š
    - ç§»é™¤ diff_context å­—æ®µ
    - ç§»é™¤ confirmed_issues å­—æ®µ
    - ç§»é™¤ metadata å­—æ®µ
    - åˆå¹¶ work_list, expert_tasks, expert_results ä¸º risk_analyses å­—æ®µ
    - final_report å­—æ®µæ”¾åœ¨æœ€å
    - risk_analyses ä¸­ä¸åŒ…å« validated_item
    
    Args:
        obj: å¯èƒ½åŒ…å«ä¸å¯åºåˆ—åŒ–å¯¹è±¡çš„å­—å…¸ã€‚
    
    Returns:
        ä»…åŒ…å«å¯åºåˆ—åŒ–å€¼çš„å­—å…¸ã€‚
    """
    if not isinstance(obj, dict):
        return obj
    
    result = {}
    for key, value in obj.items():
        # Remove diff_context field
        if key == "diff_context":
            continue
        
        if key == "metadata":
            # Skip metadata - we'll access expert_analyses from it but not include it in output
            continue
        elif key in ["work_list", "expert_tasks", "expert_results", "confirmed_issues"]:
            # Skip these keys - they will be merged into risk_analyses or removed
            continue
        elif key == "final_report":
            # Skip final_report here - will be added at the end
            continue
        elif isinstance(value, dict):
            result[key] = make_results_serializable(value)
        elif isinstance(value, list):
            result[key] = [
                make_results_serializable(item) if isinstance(item, dict) else item
                for item in value
            ]
        else:
            # Try to serialize, skip if not serializable
            try:
                json.dumps(value)
                result[key] = value
            except (TypeError, ValueError):
                result[key] = str(value)
    
    # Merge work_list, expert_tasks, expert_results into risk_analyses
    expert_analyses = obj.get("metadata", {}).get("expert_analyses", [])
    if expert_analyses:
        # Create a map from (file_path, line_number, risk_type) to expert_analysis
        analysis_map = {}
        for analysis in expert_analyses:
            file_path = analysis.get("file_path", "")
            line_number = analysis.get("line_number", [0, 0])
            risk_type = analysis.get("risk_type", "")
            key = (file_path, tuple(line_number) if isinstance(line_number, list) else line_number, risk_type)
            analysis_map[key] = analysis
        
        # Build risk_analyses list by matching work_list items with expert_analyses
        risk_analyses = []
        work_list = obj.get("work_list", [])
        
        for risk_item in work_list:
            file_path = risk_item.get("file_path", "")
            line_number = risk_item.get("line_number", [0, 0])
            risk_type = risk_item.get("risk_type", "")
            key = (file_path, tuple(line_number) if isinstance(line_number, list) else line_number, risk_type)
            
            analysis = analysis_map.get(key, {})
            
            # Build merged entry (without validated_item)
            merged_entry = {
                "risk_item": risk_item,  # åŸå§‹é£é™©é¡¹
                "result": analysis.get("result", {}),  # åˆ†æç»“æœ
                "messages": serialize_messages(analysis.get("messages", []))  # å¯¹è¯å†å²
            }
            risk_analyses.append(merged_entry)
        
        result["risk_analyses"] = risk_analyses
    
    # Add final_report at the end
    final_report = obj.get("final_report", "")
    if final_report:
        result["final_report"] = final_report
    
    return result


def serialize_messages(messages: list) -> list:
    """åºåˆ—åŒ– LangChain æ¶ˆæ¯åˆ—è¡¨ã€‚
    
    ä¸åŒ…å« tool_calls å­—æ®µï¼Œå› ä¸ºå·¥å…·è°ƒç”¨ä¿¡æ¯å·²ç»åœ¨ ToolMessage çš„ content ä¸­ã€‚
    
    Args:
        messages: LangChain æ¶ˆæ¯åˆ—è¡¨ã€‚
    
    Returns:
        å¯åºåˆ—åŒ–çš„æ¶ˆæ¯å­—å…¸åˆ—è¡¨ã€‚
    """
    serialized = []
    for msg in messages:
        msg_dict = {
            "type": type(msg).__name__,
            "content": getattr(msg, 'content', str(msg))
        }
        
        # ä¸åŒ…å« tool_calls å­—æ®µï¼Œå› ä¸ºå·¥å…·è°ƒç”¨ä¿¡æ¯å·²ç»åœ¨ ToolMessage çš„ content ä¸­
        
        if hasattr(msg, 'name'):
            msg_dict["name"] = msg.name
        
        if hasattr(msg, 'tool_call_id'):
            msg_dict["tool_call_id"] = msg.tool_call_id
        
        serialized.append(msg_dict)
    
    return serialized
